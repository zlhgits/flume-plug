a1.sources = s-1
a1.channels = c-1
# sink配置容错failover，根据优先级配置，会先启用k-1，k-1挂了后再启用k-2
a1.sinks = k-1 k-2
#########source##########
a1.sources.s-1.type = com.zlh.flume.source.JsonSource
a1.sources.s-1.db.url = jdbc:mysql://192.168.1.5:3306/zndata
a1.sources.s-1.db.user = root
a1.sources.s-1.db.passwd = znckj@95
# 使用${YYYYMM}变量。
a1.sources.s-1.s.table= test_kafka_failedmsg_${YYYYMM}
a1.sources.s-1.s.field= sid
a1.sources.s-1.batch.size = 100
a1.sources.s-1.max.rows = 500
########## channel########
a1.channels.c-1.type = memory
# 通道队列的最大长度
a1.channels.c-1.capacity = 100000
# putList和takeList队列的最大长度，sink从capacity中抓取batchsize个event
#，放到这个队列。此参数最好比capacity小，比sink的batchsize大。
a1.channels.c-1.transactionCapacity = 1000
a1.channels.c-1.byteCapacityBufferPercentage = 200
### 默认值等于JVM可用的最大内存的80%，可以不配置
# a1.channels.c-1.byteCapacity = 800000
########配置sink的failover########
#配置failover的关键，需要有一个sink group
a1.sinkgroups = sg-1
a1.sinkgroups.sg-1.sinks = k-1 k-2
#处理的类型是failover
a1.sinkgroups.sg-1.processor.type = failover
#优先级，数字越大优先级越高，每个sink的优先级必须不相同
a1.sinkgroups.sg-1.processor.priority.k-1 = 5
a1.sinkgroups.sg-1.processor.priority.k-2 = 10
#设置为10秒
a1.sinkgroups.sg-1.processor.maxpenalty = 10000

######### sinks 1 #########
a1.sinks.k-1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k-1.serializer.class=kafka.serializer.StringEncoder
a1.sinks.k-1.kafka.topic = testuser
a1.sinks.k-1.kafka.bootstrap.servers = node-hadoop-dev1:9092,node-hadoop-dev2:9092,node-hadoop-dev3:9092
a1.sinks.k-1.kafka.producer.acks = 1
a1.sinks.k-1.kafka.batchSize = 100
######### sinks 2 #########
a1.sinks.k-2.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k-2.serializer.class=kafka.serializer.StringEncoder
a1.sinks.k-2.topic = testuser
a1.sinks.k-2.bootstrap.servers =node-hadoop-dev1:9092,node-hadoop-dev2:9092,node-hadoop-dev3:9092
a1.sinks.k-2.producer.acks = 1
a1.sinks.k-2.batchSize = 500

a1.sources.s-1.channels=c-1
a1.sinks.k-1.channel = c-1
a1.sinks.k-2.channel = c-1